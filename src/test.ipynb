{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83147d4d-2936-49d5-a04e-9ce980cc92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========public pkgs========\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "#========= private pkgs==========================\n",
    "from load_data import custom_datasets\n",
    "from load_data import custom_transform\n",
    "\n",
    "from load_data_h5py import SDFDataset\n",
    "from SDF_VAE_improved import SDF_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105f3da5-5f95-4eee-89d4-9d2a23c30184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================Load configuration file===============\n",
    "with open('./config_cluster.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Extract configuration parameters\n",
    "batch_size = config['model_params']['batch_size']\n",
    "latent_dim = config['model_params']['latent_dim']\n",
    "beta = config['model_params']['beta']\n",
    "learning_rate = config['train_params']['learning_rate']\n",
    "epochs = config['train_params']['epochs']\n",
    "manual_seed = config['random_seed']['manual_seed']\n",
    "cuda_manual_seed = config['random_seed']['cuda_manual_seed']\n",
    "loading_checkpoint = config['train_params']['loading_checkpoint']\n",
    "# Paths from configuration\n",
    "data_path_train = config['Path']['train_data_path']\n",
    "data_path_test = config['Path']['test_data_path']\n",
    "save_path = config['Path']['save_path']\n",
    "checkpoint_path = config['Path']['log_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194112dd-76b4-4b61-b816-9912d40dae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed(cuda_manual_seed)\n",
    "sdf_dimen = 30\n",
    "# load test and train data\n",
    "dataset_train = SDFDataset(data_path_train)\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_train = SDFDataset(data_path_test)\n",
    "loader_test = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = SDF_VAE(input_channels=1, latent_dim=latent_dim, D=sdf_dimen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041e7803-23d8-4839-ad90-85cfa861fc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "2 GPUS are available\n"
     ]
    }
   ],
   "source": [
    "# Setup device (GPU/CPU)\n",
    "if torch.cuda.is_available(): # GPU is available\n",
    "    print('GPU is available')\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        print(str(torch.cuda.device_count()),'GPUS are available')\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    GPU = True\n",
    "    model.to(device)\n",
    "else:  # only cpu is available\n",
    "    print('CPU is only available')\n",
    "    GPU = False\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92175283-984e-4f60-ac21-5af880ba0018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7db0170-878a-49de-a433-919506f51160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def lossfunc(sdf,sdf_hat,iso,iso_hat,mu,logvar,beta):\n",
    "    \"\"\"\n",
    "    Computes the Variational Autoencoder (VAE) loss function, combining reconstruction loss and KL divergence.\n",
    "    Args\n",
    "    Returns:\n",
    "        torch.Tensor: The computed loss value.\n",
    "    \"\"\"\n",
    "    sdf_loss = F.mse_loss(sdf_hat, sdf,reduction = 'sum')\n",
    "    iso_loss = F.mse_loss(iso_hat, iso,reduction = 'sum')*40**3\n",
    "    # iso_loss = F.mse_loss(iso_hat, iso,reduction = 'sum')*30**3 # for another case\n",
    "    recons_loss = sdf_loss+ iso_loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # kl_loss = torch.mean(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim = 1), dim = 0)\n",
    "    return recons_loss + beta* kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9888aa4-9469-4365-b462-1efc50a36140",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea7b55-98a0-4e78-bfd6-8b8f1482d5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss:4094.3387\n",
      "====> Epoch: 1 Average loss:764.0978\n",
      "====> Epoch: 2 Average loss:537.1432\n",
      "====> Epoch: 3 Average loss:469.4322\n",
      "====> Epoch: 4 Average loss:356.7168\n",
      "====> Epoch: 5 Average loss:318.7557\n",
      "====> Epoch: 6 Average loss:282.5344\n",
      "====> Epoch: 7 Average loss:267.4229\n",
      "====> Epoch: 8 Average loss:229.5969\n",
      "====> Epoch: 9 Average loss:224.3178\n",
      "====> Epoch: 10 Average loss:218.0839\n",
      "====> Epoch: 11 Average loss:217.3153\n",
      "====> Epoch: 12 Average loss:207.0659\n",
      "====> Epoch: 13 Average loss:205.6220\n",
      "====> Epoch: 14 Average loss:199.6014\n",
      "====> Epoch: 15 Average loss:194.8342\n",
      "====> Epoch: 16 Average loss:195.3373\n",
      "====> Epoch: 17 Average loss:193.7658\n",
      "====> Epoch: 18 Average loss:186.7970\n",
      "====> Epoch: 19 Average loss:182.2026\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint if specified\n",
    "if loading_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_path+'checkpoint.tar')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    current_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "else: # use the initial model and optimiser\n",
    "    current_epoch = 0\n",
    "    \n",
    "for epoch in range(current_epoch, epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    mu_list = list()\n",
    "    sdf_test_list = list()\n",
    "    isov_test_list = list()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for sdf_data, isovalues in loader_train:\n",
    "        sdf_data = sdf_data.to(device)\n",
    "        isovalues = isovalues.to(device)\n",
    "        sdf_hat,iso_hat,mu,logvar = model(sdf_data,isovalues)\n",
    "        mu_list.append(mu.detach()) # save latent vector\n",
    "        #==== forwad pass\n",
    "        loss = lossfunc(sdf_data,sdf_hat,isovalues,iso_hat,mu,logvar,beta)\n",
    "        train_loss += loss.item()\n",
    "        #==== backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #=== save model \n",
    "    if (epoch) % 4 == 0: # save model every 40 steps\n",
    "        mu_list = torch.cat(mu_list,dim=0)\n",
    "        save_model = 'VAEmodel_'+str(epoch) + '.pt'\n",
    "\n",
    "        # if GPU:\n",
    "        #     torch.save(model.module.state_dict(), save_path+save_model) # save module on GPU\n",
    "        # else:\n",
    "        torch.save(model.state_dict(), save_path+save_model) # save model on CPU \n",
    "\n",
    "        save_mu = 'mu_list_'+str(epoch) + '.pt'\n",
    "        torch.save(mu_list, save_path+save_mu)\n",
    "        # ===== checke the loss function on test dataset\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            mu_list_test = list()\n",
    "            test_loss = 0\n",
    "            for sdf_data, isovalues in loader_test:\n",
    "                sdf_data = sdf_data.to(device)\n",
    "                isovalues = isovalues.to(device)\n",
    "                sdf_hat,iso_hat,mu,logvar = model(sdf_data,isovalues)\n",
    "                loss = lossfunc(sdf_data,sdf_hat,isovalues,iso_hat,mu,logvar,beta)\n",
    "                test_loss += loss.item()\n",
    "                mu_list_test.append(mu.detach())\n",
    "                sdf_test_list.append(sdf_data.detach())\n",
    "                isov_test_list.append(isovalues.detach())\n",
    "            mu_list_test = torch.cat(mu_list_test,dim=0)\n",
    "            save_mu = 'mu_list_test_'+str(epoch) + '.pt'\n",
    "            torch.save(mu_list_test, save_path+save_mu)\n",
    "            \n",
    "            sdf_test_list = torch.cat(sdf_test_list,dim=0)\n",
    "            save_sdf_test = 'sdf_test_'+str(epoch) + '.pt'\n",
    "\n",
    "            iso_test_list = torch.cat(isov_test_list,dim=0)\n",
    "            iso_sdf_test = 'iso_test_'+str(epoch) + '.pt'\n",
    "            torch.save(iso_test_list, save_path+iso_sdf_test)\n",
    "            \n",
    "\n",
    "\n",
    "    print(f'====> Epoch: {epoch} Average loss:{train_loss/len(loader_train.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063f1aa-be85-49a9-af52-6bc093c7a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% save checkpoint\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.module.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, checkpoint_path+'checkpoint.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f213567-61c2-410b-8d8e-8edb4f367361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab308f-8149-496a-b285-b30ef88929fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1d574-d2c1-4f9f-9fd0-b0d4c35bbbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fdedf8-d4c0-4d3b-8cc1-63d9e95352b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch_cuda]",
   "language": "python",
   "name": "conda-env-.conda-pytorch_cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
